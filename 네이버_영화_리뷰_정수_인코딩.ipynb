{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "네이버 영화 리뷰 - 정수 인코딩.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "73dtegAmAAEK"
      },
      "source": [
        "# **네이버 영화 리뷰 - 정수 인코딩**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MF46U5C8vp8S"
      },
      "source": [
        "구글 드라이브 마운트"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p3vGxj1OvnC8",
        "outputId": "0cfb4e75-e1e7-44b3-9c07-9a97c068b01d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aw4VU8fTv2sj"
      },
      "source": [
        "토큰화 데이터 불러오기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vTAO10Liv2-z"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "x_train_tokenized = np.load(\"/content/drive/MyDrive/ml_data/NaverMovieReview/x_train_tokenized.npy\", allow_pickle=True)\n",
        "x_test_tokenized = np.load(\"/content/drive/MyDrive/ml_data/NaverMovieReview/x_test_tokenized.npy\", allow_pickle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rX7QQkHawg3O",
        "outputId": "35ff019e-8f75-4d73-f8fb-ae1af207757e"
      },
      "source": [
        "x_train_tokenized[:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([list(['아', '더', '빙', '진짜', '짜증', '나', '네요', '목소리']),\n",
              "       list(['흠', '포스터', '보고', '초딩', '영화', '줄', '오버', '연기', '조차', '가볍', '않', '구나']),\n",
              "       list(['너무', '재', '밓었다그래서보는것을추천한다']),\n",
              "       list(['교도소', '이야기', '구먼', '솔직히', '재미', '없', '평점', '조정']),\n",
              "       list(['사이몬페그', '익살', '스런', '연기', '돋보였', '던', '영화', '스파이더맨', '에서', '늙', '어', '보이', '기', '만', '했', '던', '커스틴', '던스트', '너무나', '이뻐', '보였'])],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i_QoDGmjxFzr",
        "outputId": "fcb9f031-8973-42e2-dd4b-35e5940c6231"
      },
      "source": [
        "x_test_tokenized[:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([list(['굳', 'ㅋ']),\n",
              "       list(['뭐', '야', '평점', '나쁘', '진', '않', '지만', '점', '짜리', '더더욱', '아니', '잖아']),\n",
              "       list(['지루', '않', '은데', '완전', '막장', '돈', '주', '보', '기']),\n",
              "       list(['만', '아니', '었', '어도', '별', '다섯', '개', '줬', '텐데', '왜', '로', '나와서', '제', '심기', '불편', '죠']),\n",
              "       list(['음악', '주', '된', '최고', '음악', '영화'])], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nBVfQ2G5wwKH"
      },
      "source": [
        "단어 집합 분석"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uFG_F8atxxqa"
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(x_train_tokenized)\n",
        "\n",
        "threshold = 2\n",
        "total_cnt = len(tokenizer.word_index) # 단어의 수"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZlP9MUY_xzCr",
        "outputId": "e20e5463-98f4-490a-8f9a-324479d5b4ab"
      },
      "source": [
        "total_cnt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "49942"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gIgB-IO4x8x8",
        "outputId": "d15e868e-ca39-4969-d638-de273aa68930"
      },
      "source": [
        "rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n",
        "total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\n",
        "rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\n",
        "\n",
        "# 단어와 빈도수의 쌍(pair)을 key와 value로 받는다.\n",
        "for key, value in tokenizer.word_counts.items():\n",
        "    total_freq = total_freq + value\n",
        "\n",
        "    # 단어의 등장 빈도수가 threshold보다 작으면\n",
        "    if (value < threshold):\n",
        "        rare_cnt = rare_cnt + 1\n",
        "        rare_freq = rare_freq + value\n",
        "\n",
        "print(\"단어 집합(vocabulary)의 크기: {:,}\".format(total_cnt))\n",
        "print(\"등장 빈도가 {}번 이하인 희귀 단어의 수: {:,}개\".format(threshold - 1, rare_cnt))\n",
        "print(\"단어 집합에서 희귀 단어의 비율: {:.2f}%\".format(rare_cnt / total_cnt * 100))\n",
        "print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율: {:.2f}%\".format(rare_freq / total_freq * 100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "단어 집합(vocabulary)의 크기: 49,942\n",
            "등장 빈도가 1번 이하인 희귀 단어의 수: 21,313개\n",
            "단어 집합에서 희귀 단어의 비율: 42.68%\n",
            "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 1.19%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dWIMFCRMw70h",
        "outputId": "5a912be6-0aa1-4c13-9a53-3af94a5c2f80"
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(x_train_tokenized)\n",
        "\n",
        "threshold = 2\n",
        "total_cnt = len(tokenizer.word_index) # 단어의 수\n",
        "rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n",
        "total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\n",
        "rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\n",
        "\n",
        "# 단어와 빈도수의 쌍(pair)을 key와 value로 받는다.\n",
        "for key, value in tokenizer.word_counts.items():\n",
        "    total_freq = total_freq + value\n",
        "\n",
        "    # 단어의 등장 빈도수가 threshold보다 작으면\n",
        "    if (value < threshold):\n",
        "        rare_cnt = rare_cnt + 1\n",
        "        rare_freq = rare_freq + value\n",
        "\n",
        "print(\"단어 집합(vocabulary)의 크기: {:,}\".format(total_cnt))\n",
        "print(\"등장 빈도가 {}번 이하인 희귀 단어의 수: {:,}개\".format(threshold - 1, rare_cnt))\n",
        "print(\"단어 집합에서 희귀 단어의 비율: {:.2f}%\".format(rare_cnt / total_cnt * 100))\n",
        "print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율: {:.2f}%\".format(rare_freq / total_freq * 100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "단어 집합(vocabulary)의 크기: 49,942\n",
            "등장 빈도가 1번 이하인 희귀 단어의 수: 21,313개\n",
            "단어 집합에서 희귀 단어의 비율: 42.68%\n",
            "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 1.19%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N5OKxX3JzbN4"
      },
      "source": [
        "단어 집합의 최대 크기 제한"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_UeORt92zjMa",
        "outputId": "e7bd483f-900a-40de-c64e-efe8ae6a42b9"
      },
      "source": [
        "# 희귀 단어(등장 빈도수가 1이하인 단어) 수를 제외\n",
        "vocab_size = total_cnt - rare_cnt + 2\n",
        "print(\"단어 집합의 크기 : {:,}\".format(vocab_size))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "단어 집합의 크기 : 28,631\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tOVhiXl9zpXl"
      },
      "source": [
        "정수 인코딩"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zpZd6aGhzpAJ"
      },
      "source": [
        "tokenizer = Tokenizer(vocab_size, oov_token = \"OOV\")\n",
        "tokenizer.fit_on_texts(x_train_tokenized)\n",
        "x_train_encoded = tokenizer.texts_to_sequences(x_train_tokenized)\n",
        "x_test_encoded = tokenizer.texts_to_sequences(x_test_tokenized)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P3s8W4Cr0h8X",
        "outputId": "f196e69a-9452-4a78-ea33-9ccb87d0cc8f"
      },
      "source": [
        "x_train_encoded[:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([list([20, 58, 888, 26, 206, 7, 21, 692]),\n",
              "       list([970, 474, 484, 629, 2, 102, 1547, 39, 859, 942, 30, 356]),\n",
              "       list([11, 184, 1]), list([8029, 134, 4127, 269, 77, 5, 44, 3319]),\n",
              "       list([21623, 8481, 1044, 39, 2695, 46, 2, 2618, 27, 1111, 22, 318, 29, 9, 28, 46, 15305, 21624, 385, 2843, 1670])],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XlyscZFG0kt_",
        "outputId": "e8f60680-4c0e-4e60-840d-60ffe81b0f3c"
      },
      "source": [
        "x_test_encoded[:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([list([781, 119]),\n",
              "       list([69, 100, 44, 891, 306, 30, 24, 31, 590, 3394, 55, 848]),\n",
              "       list([80, 30, 209, 116, 320, 129, 41, 3, 29]),\n",
              "       list([9, 55, 8, 422, 224, 2004, 110, 511, 538, 49, 16, 585, 317, 19685, 785, 268]),\n",
              "       list([215, 41, 137, 42, 215, 2])], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LVOBOPn3zzZJ"
      },
      "source": [
        "정수 인코딩 데이터 저장"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_EjXXbj_zdDE"
      },
      "source": [
        "x_train_encoded = np.array(x_train_encoded, dtype=\"object\")\n",
        "x_test_encoded = np.array(x_test_encoded, dtype=\"object\")\n",
        "np.save(\"/content/drive/MyDrive/ml_data/NaverMovieReview/x_train_encoded.npy\", x_train_encoded, allow_pickle=True)\n",
        "np.save(\"/content/drive/MyDrive/ml_data/NaverMovieReview/x_test_encoded.npy\", x_test_encoded, allow_pickle=True)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}